{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport tensorflow_decision_forests as tfdf\nprint(f\"Found TF-DF {tfdf.__version__}\")\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-04-29T10:03:11.379326Z","iopub.execute_input":"2023-04-29T10:03:11.379827Z","iopub.status.idle":"2023-04-29T10:03:11.391275Z","shell.execute_reply.started":"2023-04-29T10:03:11.379774Z","shell.execute_reply":"2023-04-29T10:03:11.389939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"serving_df = pd.read_csv(\"/kaggle/input/titanic/test.csv\")\nserving_df.head()\nserving_df","metadata":{"execution":{"iopub.status.busy":"2023-04-29T10:03:11.433308Z","iopub.execute_input":"2023-04-29T10:03:11.433738Z","iopub.status.idle":"2023-04-29T10:03:11.467546Z","shell.execute_reply.started":"2023-04-29T10:03:11.433684Z","shell.execute_reply":"2023-04-29T10:03:11.466153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2023-04-29T10:03:11.470092Z","iopub.execute_input":"2023-04-29T10:03:11.470782Z","iopub.status.idle":"2023-04-29T10:03:11.496200Z","shell.execute_reply.started":"2023-04-29T10:03:11.470730Z","shell.execute_reply":"2023-04-29T10:03:11.494768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Preparar base de datos:\nAplicar las siguientes tranformacion en la base de datos\n\n1. Tokenizazr los nombres.\"Seather, Mr. Simon Sivertsen\" will become [\"Seather\", \"Mr.\", \"Simon\", \"Sivertsen\"].\n2. Extraer los prefijos en los tickets. Ejemplo \"SOTON/O.Q. 3101262\" VA A SER \"SOTON/0.Q.\" y 31012262","metadata":{}},{"cell_type":"code","source":"def preprocess(df):\n    df = df.copy()\n    \n    def normalize_name(x):\n        return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n    \n    def ticket_number(x):\n        return x.split(\" \")[-1]\n    \n    def ticket_item(x):\n        items = x.split(\" \")\n        if len(items) == 1:\n            return \"NONE\"\n        return \"_\".join(items[0:-1])\n    \n    df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)\n    return df\n\npreprocessed_train_df = preprocess(train_df)\npreprocessed_serving_df = preprocess(serving_df)\n\npreprocessed_train_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T10:03:11.497867Z","iopub.execute_input":"2023-04-29T10:03:11.498317Z","iopub.status.idle":"2023-04-29T10:03:11.532288Z","shell.execute_reply.started":"2023-04-29T10:03:11.498270Z","shell.execute_reply":"2023-04-29T10:03:11.530894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Mantengamos la lista de las características de entrada del modelo. En particular, no queremos entrenar nuestro modelo con las características \"PassengerId\" y \"Ticket\".","metadata":{}},{"cell_type":"code","source":"input_features = list(preprocessed_train_df.columns)\ninput_features.remove(\"Ticket\")\ninput_features.remove(\"PassengerId\")\ninput_features.remove(\"Survived\")\n#input_features.remove(\"Ticket_number\")\n\nprint(f\"Input features: {input_features}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-29T10:03:11.535291Z","iopub.execute_input":"2023-04-29T10:03:11.535648Z","iopub.status.idle":"2023-04-29T10:03:11.542469Z","shell.execute_reply.started":"2023-04-29T10:03:11.535614Z","shell.execute_reply":"2023-04-29T10:03:11.541273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Convertir el dataset Pandas en dataset TensorFlow ","metadata":{}},{"cell_type":"code","source":"def tokenize_names(features, labels=None):\n    \"\"\"Divida los nombres en tokens. TF-DF puede consumir tokens de texto de forma nativa.\"\"\"\n    features[\"Name\"] =  tf.strings.split(features[\"Name\"])\n    return features, labels\n\ntrain_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_train_df,label=\"Survived\").map(tokenize_names)\nserving_ds = tfdf.keras.pd_dataframe_to_tf_dataset(preprocessed_serving_df).map(tokenize_names)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T10:03:11.544176Z","iopub.execute_input":"2023-04-29T10:03:11.544576Z","iopub.status.idle":"2023-04-29T10:03:11.700236Z","shell.execute_reply.started":"2023-04-29T10:03:11.544538Z","shell.execute_reply":"2023-04-29T10:03:11.698931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Entrenar el modelo con parametros por defecto\n\nEn primer lugar, vamos a entrenar un modelo GradientBoostedTreesModel con los parámetros por defecto.","metadata":{}},{"cell_type":"code","source":"model = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0, # very few logs\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features=True, #only use the features in \"features\"\n    random_seed=1234,\n)\nmodel.fit(train_ds)\n\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Losss:{self_evaluation.loss}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-29T10:03:11.702183Z","iopub.execute_input":"2023-04-29T10:03:11.702520Z","iopub.status.idle":"2023-04-29T10:03:12.709314Z","shell.execute_reply.started":"2023-04-29T10:03:11.702488Z","shell.execute_reply":"2023-04-29T10:03:12.708279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El resultado muestra que el modelo ha sido entrenado y evaluado en el conjunto de entrenamiento. La precisión del modelo en el conjunto de entrenamiento es de 0.826, lo que es un buen punto de partida.","metadata":{}},{"cell_type":"markdown","source":"## Entrenar el modelo con parámetros por defecto mejorados\nAhora utilizarás algunos parámetros específicos al crear el modelo GBT","metadata":{}},{"cell_type":"code","source":"model = tfdf.keras.GradientBoostedTreesModel(\n    verbose=0, # very few logs\n    features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n    exclude_non_specified_features=True, # Only use the features in \"features\"\n    \n    #num_trees=2000,\n    \n    # Only for GBT.\n    # A bit slower, but great to understand the model.\n    # compute_permutation_variable_importance=True,\n    \n    # Change the default hyper-parameters\n    # hyperparameter_template=\"benchmark_rank1@v1\",\n    \n    #num_trees=1000,\n    #tuner=tuner\n    \n    min_examples=1,\n    categorical_algorithm=\"RANDOM\",\n    #max_depth=4,\n    shrinkage=0.05,\n    #num_candidate_attributes_ratio=0.2,\n    split_axis=\"SPARSE_OBLIQUE\",\n    sparse_oblique_normalization=\"MIN_MAX\",\n    sparse_oblique_num_projections_exponent=2.0,\n    num_trees=2000,\n    #validation_ratio=0.0,\n    random_seed=1234\n\n)\nmodel.fit(train_ds)\n\nself_evaluation = model.make_inspector().evaluation()\nprint(f\"Accuracy: {self_evaluation.accuracy} Loss:{self_evaluation.loss}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-29T10:03:12.710767Z","iopub.execute_input":"2023-04-29T10:03:12.712068Z","iopub.status.idle":"2023-04-29T10:03:14.127637Z","shell.execute_reply.started":"2023-04-29T10:03:12.712018Z","shell.execute_reply":"2023-04-29T10:03:14.126250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El output muestra que el modelo ha sido cargado desde el directorio especificado en el mensaje [INFO], y evaluado en el conjunto de entrenamiento. La precisión del modelo en el conjunto de entrenamiento es 0.7608, lo que puede ser un poco inferior a lo que se obtuvo previamente en el modelo básico.","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-29T10:03:14.129276Z","iopub.execute_input":"2023-04-29T10:03:14.129796Z","iopub.status.idle":"2023-04-29T10:03:14.147797Z","shell.execute_reply.started":"2023-04-29T10:03:14.129754Z","shell.execute_reply":"2023-04-29T10:03:14.146441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El modelo presentado es un Gradient Boosted Trees Model para la tarea de clasificación, con una única capa y 11 características de entrada, como la edad, la tarifa y el sexo. La precisión del modelo se mejoró con el tiempo a medida que se agregaron más iteraciones, y la precisión final fue del 93.87% para el conjunto de entrenamiento y del 77.17% para el conjunto de validación. La importancia de las variables se muestra en diferentes categorías, como INV_MEAN_MIN_DEPTH, NUM_AS_ROOT, NUM_NODES y SUM_SCORE. El modelo tiene un total de 33 árboles, con un promedio de 55 nodos por árbol. El tipo de condición en los nodos es principalmente oblicua, contiene condiciones y contiene condición de mapa de bits.","metadata":{}},{"cell_type":"markdown","source":"## Hacer predicciones","metadata":{}},{"cell_type":"code","source":"def prediction_to_kaggle_format(model, threshold=0.5):\n    proba_survive = model.predict(serving_ds, verbose=0)[:,0]\n    return pd.DataFrame({\n        \"PassengerId\": serving_df[\"PassengerId\"],\n        \"Survived\": (proba_survive >= threshold).astype(int)\n    })\n\ndef make_submission(kaggle_predictions):\n    path=\"/kaggle/working/submission.csv\"\n    kaggle_predictions.to_csv(path, index=False)\n    print(f\"Submission exported to {path}\")\n    \nkaggle_predictions = prediction_to_kaggle_format(model)\nmake_submission(kaggle_predictions)\n!head /kaggle/working/submission.csv","metadata":{"execution":{"iopub.status.busy":"2023-04-29T10:03:14.150185Z","iopub.execute_input":"2023-04-29T10:03:14.150546Z","iopub.status.idle":"2023-04-29T10:03:15.356423Z","shell.execute_reply.started":"2023-04-29T10:03:14.150512Z","shell.execute_reply":"2023-04-29T10:03:15.354984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"El código presentado es una función que convierte las predicciones del modelo en un formato que es compatible con la competencia de Kaggle y luego las exporta como un archivo CSV en la ubicación de trabajo actual en Kaggle.\n\nLa función prediction_to_kaggle_format toma el modelo entrenado y utiliza el conjunto de datos de prueba serving_ds para hacer predicciones. A continuación, la función crea un DataFrame de Pandas que contiene las columnas \"PassengerId\" y \"Survived\", donde \"PassengerId\" es el identificador del pasajero y \"Survived\" es la predicción binaria de si ese pasajero sobrevivió o no. La predicción se realiza mediante el umbral (threshold) de probabilidad especificado como parámetro en la función. Si la probabilidad de supervivencia del pasajero es mayor o igual que el umbral, entonces la predicción es 1, de lo contrario, es 0.\n\nLa función make_submission toma el DataFrame creado por prediction_to_kaggle_format y lo guarda como un archivo CSV en la ubicación especificada en el parámetro path. Finalmente, el código muestra las primeras líneas del archivo CSV creado utilizando el comando !head.\n\nEn general, el objetivo de este código es hacer predicciones sobre el conjunto de datos de prueba y crear un archivo de sumisión que pueda ser cargado en la plataforma Kaggle para evaluar el rendimiento del modelo en una competencia de aprendizaje automático.","metadata":{}},{"cell_type":"markdown","source":"## Entrenamiento de un modelo con ajuste de hiperparámetros\nLa sintonización de hiperparámetros se activa especificando el argumento constructor del sintonizador del modelo. El objeto tuner contiene toda la configuración del tuner (espacio de búsqueda, optimizador, prueba y objetivo).","metadata":{}},{"cell_type":"code","source":"tuner = tfdf.tuner.RandomSearch(num_trials=1000)\ntuner.choice(\"min_examples\", [2, 5, 7, 10])\ntuner.choice(\"categorical_algorithm\", [\"CART\", \"RANDOM\"])\n\nlocal_search_space = tuner.choice(\"growing_strategy\", [\"LOCAL\"])\nlocal_search_space.choice(\"max_depth\", [3, 4, 5, 8])\n\nglobal_search_space = tuner.choice(\"growing_strategy\", [\"BEST_FIRST_GLOBAL\"], merge=True)\nglobal_search_space.choice(\"max_num_nodes\", [16, 32, 64, 128, 2256])\n\n#tuner.choice(\"use_hessian_gain\", [True, False])\ntuner.choice(\"shrinkage\", [0.02, 0.05, 0.10, 0.15])\ntuner.choice(\"num_candidate_attributes_ratio\", [0.2, 0.5, 0.9, 1.0])\n\n\ntuner.choice(\"split_axis\", [\"AXIS_ALIGNED\"])\noblique_space = tuner.choice(\"split_axis\", [\"SPARSE_OBLIQUE\"], merge=True)\noblique_space.choice(\"sparse_oblique_normalization\",\n                    [\"NONE\", \"STANDARD_DEVIATION\", \"MIN_MAX\"])\noblique_space.choice(\"sparse_oblique_weights\", [\"BINARY\", \"CONTINUOUS\"])\noblique_space.choice(\"sparse_oblique_num_projections_exponent\", [1.0, 1.5])\n\n# Tune the model. Notice the `tuner=tuner`.\ntuned_model = tfdf.keras.GradientBoostedTreesModel(tuner=tuner)\ntuned_model.fit(train_ds, verbose=0)\n\ntuned_self_evaluation = tuned_model.make_inspector().evaluation()\nprint(f\"Accuracy: {tuned_self_evaluation.accuracy} Loss:{tuned_self_evaluation.loss}\")","metadata":{"execution":{"iopub.status.busy":"2023-04-29T10:03:15.360874Z","iopub.execute_input":"2023-04-29T10:03:15.361303Z","iopub.status.idle":"2023-04-29T10:05:18.189391Z","shell.execute_reply.started":"2023-04-29T10:03:15.361263Z","shell.execute_reply":"2023-04-29T10:05:18.187988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"En esta sección se muestra cómo utilizar la optimización de hiperparámetros para mejorar el rendimiento del modelo. La optimización de hiperparámetros se realiza especificando el argumento constructor tuner del modelo. El objeto tuner contiene toda la configuración del optimizador (espacio de búsqueda, optimizador, ensayos y objetivo).\n\nSe definen diferentes espacios de búsqueda para los hiperparámetros a través de la función tuner.choice(), en la que se especifican las opciones para cada parámetro. Luego se entrena el modelo utilizando el optimizador tuner y se muestra la precisión obtenida.\n\nEl objetivo de la optimización de hiperparámetros es encontrar la mejor combinación de valores de hiperparámetros para mejorar la precisión del modelo. La optimización de hiperparámetros puede ser automatizada y es muy útil cuando se trabaja con grandes conjuntos de datos y se necesita mejorar la precisión del modelo.\n\nPara más información se recomienda seguir el tutorial de optimización de hiperparámetros automatizada.","metadata":{}},{"cell_type":"markdown","source":"## Creando un conjunto (ensemble)\nAquí crearás 100 modelos con diferentes semillas y combinarás sus resultados.\n\nEste enfoque elimina un poco los aspectos aleatorios relacionados con la creación de modelos de aprendizaje automático.\n\nEn la creación de GBT se utiliza el parámetro \"honest\". Utilizará diferentes ejemplos de entrenamiento para inferir la estructura y los valores de las hojas. Esta técnica de regularización intercambia ejemplos por estimaciones de sesgo.","metadata":{}},{"cell_type":"code","source":"predictions = None\nnum_predictions = 0\n\nfor i in range(100):\n    print(f\"i:{i}\")\n    # Possible models: GradientBoostedTreesModel or RandomForestModel\n    model = tfdf.keras.GradientBoostedTreesModel(\n        verbose=0, # Very few logs\n        features=[tfdf.keras.FeatureUsage(name=n) for n in input_features],\n        exclude_non_specified_features=True, # Only use the features in \"features\"\n\n        #min_examples=1,\n        #categorical_algorithm=\"RANDOM\",\n        ##max_depth=4,\n        #shrinkage=0.05,\n        ##num_candidate_attributes_ratio=0.2,\n        #split_axis=\"SPARSE_OBLIQUE\",\n        #sparse_oblique_normalization=\"MIN_MAX\",\n        #sparse_oblique_num_projections_exponent=2.0,\n        #num_trees=2000,\n        ##validation_ratio=0.0,\n        random_seed=i,\n        honest=True,\n    )\n    model.fit(train_ds)\n    \n    sub_predictions = model.predict(serving_ds, verbose=0)[:,0]\n    if predictions is None:\n        predictions = sub_predictions\n    else:\n        predictions += sub_predictions\n    num_predictions += 1\n\npredictions/=num_predictions\n\nkaggle_predictions = pd.DataFrame({\n        \"PassengerId\": serving_df[\"PassengerId\"],\n        \"Survived\": (predictions >= 0.5).astype(int)\n    })\n\nmake_submission(kaggle_predictions)","metadata":{"execution":{"iopub.status.busy":"2023-04-29T10:05:48.198836Z","iopub.execute_input":"2023-04-29T10:05:48.199282Z","iopub.status.idle":"2023-04-29T10:08:00.299177Z","shell.execute_reply.started":"2023-04-29T10:05:48.199243Z","shell.execute_reply":"2023-04-29T10:08:00.297788Z"},"trusted":true},"execution_count":null,"outputs":[]}]}